.PU
.TH bzip2 1
.SH NAME
bzip2, bunzip2 \- a funky-ass block-sortin file compressor, v1.0.6
.br
bzcat \- decompresses filez ta stdout
.br
bzip2recover \- recovers data from damaged bzip2 files

.SH SYNOPSIS
.ll +8
.B bzip2
.RB [ " \-cdfkqstvzVL123456789 " ]
[
.I "filenames \&..."
]
.ll -8
.br
.B bunzip2
.RB [ " \-fkvsVL " ]
[ 
.I "filenames \&..."
]
.br
.B bzcat
.RB [ " \-s " ]
[ 
.I "filenames \&..."
]
.br
.B bzip2recover
.I "filename"

.SH DESCRIPTION
.I bzip2
compresses filez rockin tha Burrows-Wheela block sorting
text compression algorithm, n' Huffman coding.  Compression is
generally considerably betta than dat  bigged up  by mo' conventional
LZ77/LZ78-based compressors, n' approaches tha performizzle of tha PPM
family of statistical compressors.

Da command-line options is deliberately straight-up similar ta 
those of 
.I GNU gzip, 
but they is not identical.

.I bzip2
expects a list of file names ta accompany the
command-line flags.  Each file is replaced by a cold-ass lil compressed version of
itself, wit tha name "original_name.bz2".  
Each compressed file
has tha same ol' dirty modification date, permissions, and, when possible,
ballershizzle as tha correspondin original, so dat these propertizzles can
be erectly restored at decompression time.  File name handlin is
naive up in tha sense dat there is no mechanizzle fo' preservin original
file names, permissions, ballerships or dates up in filesystems which lack
these concepts, or have straight-up file name length restrictions, such as
MS-DOS.

.I bzip2
and
.I bunzip2
will by default not overwrite existing
files.  If you want dis ta happen, specify tha \-f flag.

If no file names is specified,
.I bzip2
compresses from standard
input ta standard output.  In dis case,
.I bzip2
will decline to
write compressed output ta a terminal, as dis would be entirely
incomprehensible n' therefore pointless.

.I bunzip2
(or
.I bzip2 \-d) 
decompresses all
specified files.  Filez which was not pimped by 
.I bzip2
will be detected n' ignored, n' a warnin issued. Y'all KNOW dat shit, muthafucka!  
.I bzip2
attempts ta guess tha filename fo' tha decompressed file 
from dat of tha compressed file as bigs up:

       filename.bz2    becomes   filename
       filename.bz     becomes   filename
       filename.tbz2   becomes   filename.tar
       filename.tbz    becomes   filename.tar
       anyothername    becomes   anyothername.out

If tha file do not end up in one of tha recognised endings, 
.I .bz2, 
.I .bz, 
.I .tbz2
or
.I .tbz, 
.I bzip2 
complains dat it cannot
guess tha name of tha original gangsta file, n' uses tha original gangsta name
with
.I .out
appended.

As wit compression, supplyin no
filenames causes decompression from 
standard input ta standard output.

.I bunzip2 
will erectly decompress a gangbangin' file which is the
concatenation of two or mo' compressed files.  Da result is the
concatenation of tha correspondin uncompressed files.  Integrity
testin (\-t) 
of concatenated 
compressed filez be also supported.

Yo ass can also compress or decompress filez ta tha standard output by
givin tha \-c flag.  Multiple filez may be compressed and
decompressed like all dis bullshit.  Da resultin outputs is fed sequentially to
stdout.  Compression of multiple filez 
in dis manner generates a stream
containin multiple compressed file representations.  Such a stream
can be decompressed erectly only by
.I bzip2 
version 0.9.0 or
later n' shit.  Earlier versions of
.I bzip2
will stop afta decompressing
the first file up in tha stream.

.I bzcat
(or
.I bzip2 -dc) 
decompresses all specified filez to
the standard output.

.I bzip2
will read arguments from tha environment variables
.I BZIP2
and
.I BZIP,
in dat order, n' will process them
before any arguments read from tha command line.  This gives a 
convenient way ta supply default arguments.

Compression be always performed, even if tha compressed 
file is slightly
larger than tha original. It aint nuthin but tha nick nack patty wack, I still gots tha bigger sack.  Filez of less than bout one hundred bytes
tend ta git larger, since tha compression mechanizzle has a cold-ass lil constant
overhead up in tha region of 50 bytes.  Random data (includin tha output
of most file compressors) is coded at bout 8.05 bits per byte, giving
an expansion of round 0.5%.

As a self-check fo' yo' protection, 
.I 
bzip2
uses 32-bit CRCs to
make shizzle dat tha decompressed version of a gangbangin' file is identical ta the
original. It aint nuthin but tha nick nack patty wack, I still gots tha bigger sack.  This guardz against corruption of tha compressed data, and
against undetected bugs in
.I bzip2
(hopefully straight-up unlikely).  The
chancez of data corruption goin undetected is microscopic, bout one
chizzle up in four bazillion fo' each file processed. Y'all KNOW dat shit, muthafucka!  Be aware, though, that
the check occurs upon decompression, so it can only rap  that
suttin' is wrong.  It can't help you 
recover tha original gangsta uncompressed
data.  Yo ass can use 
.I bzip2recover
to try ta recover data from
damaged files.

Return joints: 0 fo' a aiiight exit, 1 fo' environmenstrual problems (file
not found, invalid flags, I/O errors, &c), 2 ta indicate a cold-ass lil corrupt
compressed file, 3 fo' a internal consistency error (eg, bug) which
caused
.I bzip2
to panic.

.SH OPTIONS
.TP
.B \-c --stdout
Compress or decompress ta standard output.
.TP
.B \-d --decompress
Force decompression. I aint talkin' bout chicken n' gravy biatch.  
.I bzip2, 
.I bunzip2 
and
.I bzcat 
are
really tha same program, n' tha decision bout what tha fuck actions ta take is
done on tha basiz of which name is used. Y'all KNOW dat shit, muthafucka!  This flag overrides that
mechanism, n' forces 
.I bzip2
to decompress.
.TP
.B \-z --compress
Da complement ta \-d: forces compression, regardless of the
invocation name.
.TP
.B \-t --test
Peep integritizzle of tha specified file(s) yo, but don't decompress em.
This straight-up performs a trial decompression n' throws away tha result.
.TP
.B \-f --force
Force overwrite of output files.  Normally,
.I bzip2 
will not overwrite
existin output files.  Also forces 
.I bzip2 
to break hard links
to files, which it otherwise wouldn't do.

bzip2 normally declines ta decompress filez which aint gots the
correct magic header bytes.  If forced (-f), however, it will pass
such filez all up in unmodified. Y'all KNOW dat shit, muthafucka!  This is how tha fuck GNU gzip behaves.
.TP
.B \-k --keep
Keep (don't delete) input filez durin compression
or decompression.
.TP
.B \-s --small
Reduce memory usage, fo' compression, decompression n' testing.  Files
are decompressed n' tested rockin a modified algorithm which only
requires 2.5 bytes per block byte.  This means any file can be
decompressed up in 2300k of memory, albeit at bout half tha aiiight speed.

Durin compression, \-s selects a funky-ass block size of 200k, which limits
memory use ta round tha same figure, all up in tha expense of yo' compression
ratio.  In short, if yo' machine is low on memory (8 megabytes or
less), use \-s fo' every last muthafuckin thang.  See MEMORY MANAGEMENT below.
.TP
.B \-q --quiet
Suppress non-essential warnin lyrics.  Lyrics pertainin to
I/O errors n' other critical events aint gonna be suppressed.
.TP
.B \-v --verbose
Verbose mode -- show tha compression ratio fo' each file processed.
Further \-vz increase tha verbositizzle level, spewin up fuckin shitloadz of
information which is primarily of interest fo' diagnostic purposes.
.TP
.B \-L --license -V --version
Display tha software version, license terms n' conditions.
.TP
.B \-1 (or \-\-fast) ta \-9 (or \-\-best)
Set tha block size ta 100 k, 200 k ..  900 k when compressing.  Has no
effect when decompressing.  See MEMORY MANAGEMENT below.
Da \-\-fast n' \-\-best aliases is primarily fo' GNU gzip 
compatibility.  In particular, \-\-fast don't make thangs
significantly fasta n' shit.  
And \-\-best merely selects tha default behaviour.
.TP
.B \--
Treats all subsequent arguments as file names, even if they start
with a thugged-out dash.  This is so you can handle filez wit names beginning
with a thugged-out dash, fo' example: bzip2 \-- \-myfilename.
.TP
.B \--repetitive-fast --repetitive-best
These flags is redundant up in versions 0.9.5 n' above.  They provided
some coarse control over tha behaviour of tha sortin algorithm in
earlier versions, which was sometimes useful naaahhmean?  0.9.5 n' above have an
improved algorithm which rendaz these flags irrelevant.

.SH MEMORY MANAGEMENT
.I bzip2 
compresses big-ass filez up in blocks.  Da block size affects
both tha compression ratio  bigged up , n' tha amount of memory needed for
compression n' decompression. I aint talkin' bout chicken n' gravy biatch.  Da flags \-1 all up in \-9
specify tha block size ta be 100,000 bytes all up in 900,000 bytes (the
default) respectively.  At decompression time, tha block size used for
compression is read from tha header of tha compressed file, and
.I bunzip2
then allocates itself just enough memory ta decompress
the file.  Since block sizes is stored up in compressed files, it bigs up
that tha flags \-1 ta \-9 is irrelevant ta n' so ignored
durin decompression.

Compression n' decompression requirements, 
in bytes, can be estimated as:

       Compression:   400k + ( 8 x block size )

       Decompression: 100k + ( 4 x block size ), or
                      100k + ( 2.5 x block size )

Larger block sizes give rapidly diminishin marginal returns.  Most of
the compression be reppin tha straight-up original gangsta two or three hundred k of block
size, a gangbangin' fact worth bearin up in mind when using
.I bzip2
on lil' small-ass machines.
It be also blingin ta appreciate dat tha decompression memory
requirement is set at compression time by tha chizzle of block size.

For filez compressed wit tha default 900k block size,
.I bunzip2
will require bout 3700 kbytes ta decompress.  To support decompression
of any file on a 4 megabyte machine, 
.I bunzip2
has a option to
decompress rockin approximately half dis amount of memory, bout 2300
kbytes.  Decompression speed be also halved, so you should use this
option only where necessary.  Da relevant flag is -s.

In general, try n' use tha phattest block size memory constraints allow,
since dat maximises tha compression  bigged up . Y'all KNOW dat shit, muthafucka!  Compression and
decompression speed is virtually unaffected by block size.

Another dope point applies ta filez which fit up in a single block
-- dat means most filez you'd encounta rockin a big-ass block size.  The
amount of real memory touched is proportionizzle ta tha size of tha file,
since tha file is smalla than a funky-ass block.  For example, compressin a gangbangin' file
20,000 bytes long wit tha flag -9 will cause tha compressor to
allocate round 7600k of memory yo, but only bust a nut on 400k + 20000 * 8 = 560
kbytez of dat shit.  Similarly, tha decompressor will allocate 3700k but only
touch 100k + 20000 * 4 = 180 kbytes.

Here be a table which summarises tha maximum memory usage fo' different
block sizes.  Also recorded is tha total compressed size fo' 14 filez of
the Calgary Text Compression Corpus totallin 3,141,622 bytes.  This
column gives some feel fo' how tha fuck compression varies wit block size.
These figures tend ta understate tha advantage of larger block sizes for
larger files, since tha Corpus is dominated by smalla files.

           Compress   Decompress   Decompress   Corpus
    Flag     usage      usage       -s usage     Size

     -1      1200k       500k         350k      914704
     -2      2000k       900k         600k      877703
     -3      2800k      1300k         850k      860338
     -4      3600k      1700k        1100k      846899
     -5      4400k      2100k        1350k      845160
     -6      5200k      2500k        1600k      838626
     -7      6100k      2900k        1850k      834096
     -8      6800k      3300k        2100k      828642
     -9      7600k      3700k        2350k      828642

.SH RECOVERING DATA FROM DAMAGED FILES
.I bzip2
compresses filez up in blocks, probably 900kbytes long.  Each
block is handled independently.  If a media or transmission error causes
a multi-block .bz2
file ta become damaged, it may be possible to
recover data from tha undamaged blocks up in tha file.

Da compressed representation of each block is delimited by a 48-bit
pattern, which make it possible ta find tha block boundaries with
reasonable certainty.  Each block also carries its own 32-bit CRC, so
damaged blocks can be distinguished from undamaged ones.

.I bzip2recover
is a simple program whose purpose is ta search for
blocks up in .bz2 files, n' write each block up tha fuck into its own .bz2 
file.  Yo ass can then use
.I bzip2 
\-t
to test the
integritizzle of tha resultin files, n' decompress dem which are
undamaged.

.I bzip2recover
takes a single argument, tha name of tha damaged file, 
and writes a fuckin shitload of filez "rec00001file.bz2",
"rec00002file.bz2", etc, containin tha  extracted  blocks.
Da  output  filenames  is  designed  so  dat tha use of
wildcardz up in subsequent processin -- fo' example,  
"bzip2 -dc  rec*file.bz2 > recovered_data" -- processes tha filez in
the erect order.

.I bzip2recover
should be of most use dealin wit big-ass .bz2
files,  as  these will contain nuff blocks.  It be clearly
futile ta use it on damaged single-block  files,  since  a
damaged  block  cannot  be recovered. Y'all KNOW dat shit, muthafucka!  If you wish ta minimise 
any potential data loss all up in media  or  transmission errors, 
you might consider compressin wit a smaller
block size.

.SH PERFORMANCE NOTES
Da sortin phase of compression gathers together similar strings up in the
file.  Because of this, filez containin straight-up long runz of repeated
symbols, like "aabaabaabaab ..."  (repeated nuff muthafuckin hundred times) may
compress mo' slowly than normal. It aint nuthin but tha nick nack patty wack, I still gots tha bigger sack.  Versions 0.9.5 n' above fare much
betta than previous versions up in dis respect.  Da ratio between
worst-case n' average-case compression time is up in tha region of 10:1.
For previous versions, dis figure was mo' like 100:1.  Yo ass can use the
\-vvvv option ta monitor progress up in pimped out detail, if you want.

Decompression speed is unaffected by these phenomena.

.I bzip2
usually allocates nuff muthafuckin megabytez of memory ta operate
in, n' then charges all over it up in a gangbangin' fairly random fashion. I aint talkin' bout chicken n' gravy biatch.  This means
that performance, both fo' compressin n' decompressing, is largely
determined by tha speed at which yo' machine can steez cache misses.
Because of this, lil' small-ass chizzlez ta tha code ta reduce tha miss rate have
been observed ta give disproportionately big-ass performizzle improvements.
I imagine 
.I bzip2
will big-ass up dopest on machines wit straight-up big-ass caches.

.SH CAVEATS
I/O error lyrics is not as helpful as they could be.
.I bzip2
tries hard ta detect I/O errors n' exit cleanly yo, but tha details of
what tha problem is sometimes seem rather misleading.

This manual page pertains ta version 1.0.6 of
.I bzip2.  
Compressed data pimped by dis version is entirely forwardz and
backwardz compatible wit tha previous hood releases, versions
0.1pl2, 0.9.0, 0.9.5, 1.0.0, 1.0.1, 1.0.2 n' above yo, but wit tha following
exception: 0.9.0 n' above can erectly decompress multiple
concatenated compressed files.  0.1pl2 cannot do this; it will stop
afta decompressin just tha straight-up original gangsta file up in tha stream.

.I bzip2recover
versions prior ta 1.0.2 used 32-bit integers ta represent
bit positions up in compressed files, so they could not handle compressed
filez mo' than 512 megabytes long.  Versions 1.0.2 n' above use
64-bit ints on some platforms which support dem (GNU supported
targets, n' Windows).  To establish whether or not bzip2recover was
built wit such a limitation, run it without arguments, n' you can put dat on yo' toast.  In any event
you can build yo ass a unlimited version if you can recompile it
with MaybeUInt64 set ta be a unsigned 64-bit integer.



.SH AUTHOR
Julian Seward, jsewardbzip.org.

http://www.bzip.org

Da scams embodied in
.I bzip2
are cuz of (at least) tha following
people: Mike Burrows n' Dizzy Wheela (for tha block sorting
transformation), Dizzy Wheela (again, fo' tha Huffman coder), Peter
Fenwick (for tha structured codin model up in tha original
.I bzip,
and nuff refinements), n' Alistair Moffat, Radford Neal n' Ian Witten
(for tha arithmetic coder up in tha original
.I bzip).  
I be much
indebted fo' they help, support n' lyrics.  See tha manual up in the
source distribution fo' pointas ta sourcez of documentation. I aint talkin' bout chicken n' gravy biatch.  Christian
von Roques encouraged mah crazy ass ta look fo' fasta sortin algorithms, so as to
speed up compression. I aint talkin' bout chicken n' gravy biatch.  Bela Lubkin encouraged mah crazy ass ta improve the
worst-case compression performance.  
Donna Robinston XMLised tha documentation.
Da bz* scripts is derived from dem of GNU gzip.
Many playas busted patches, helped
with portabilitizzle problems, lent machines, gave lyrics n' was generally
helpful.
