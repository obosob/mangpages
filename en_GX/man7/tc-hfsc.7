.TH "TC\-HFSC" 7 "31 October 2011" iproute2 Linux
.SH "NAME"
tc-hfcs \- Hierarchical Fair Service Curve
.
.SH "HISTORY & INTRODUCTION"
.
HFSC (Hierarchical Fair Service Curve) be a network packet schedulin algorithm dat was first presented at
SIGCOMM'97. Developed as a part of ALTQ (ALTernatizzle Queuing) on NetBSD, found
its way quickly ta other BSD systems, n' then all dem muthafuckin years ago became part of
the linux kernel. Right back up in yo muthafuckin ass. Still, it aint da most thugged-out ghettofab schedulin algorithm \-
especially if compared ta HTB \- n' it aint well documented fo' tha enduser n' shit. This introduction aims ta explain how tha fuck HFSC works without using
too much math (although some math it will be
inevitable).

In short HFSC aims to:
.
.RS 4
.IP \fB1)\fR 4
guarantee precise bandwidth n' delay allocation fo' all leaf classes (realtime
criterion)
.IP \fB2)\fR
allocate excess bandwidth fairly as specified by class hierarchy (linkshare &
upperlimit criterion)
.IP \fB3)\fR
minimize any discrepancy between tha steez curve n' tha actual amount of
service provided durin linksharing
.RE
.PP
.
Da main "selling" point of HFSC is feature \fB(1)\fR, which be  bigged up  by
usin nonlinear steez curves (more bout what tha fuck it straight-up is later). This is
particularly useful up in VoIP or games, where not only a guarantee of consistent
bandwidth is blingin yo, but also limitin tha initial delay of a thugged-out data stream. Note that
it mattas only fo' leaf classes (where tha actual queues are) \- thus class
hierarchy is ignored up in tha realtime case.

Feature \fB(2)\fR is well, obvious \- any algorithm featurin class hierarchy
(like fuckin HTB or CBQ) strives ta big up dis shiznit yo. HFSC do dat well, although
you might end wit unusual thangs, if you define steez curves carelessly
\- peep section CORNER CASES fo' examples.

Feature \fB(3)\fR is mentioned cuz of tha nature of tha problem. There may be
situations where itz either not possible ta guarantee steez of all curves at
the same time, and/or itz impossible ta do so fairly. Both is ghon be explained
later n' shit. Note dat dis is mainly related ta interior (aka aggregate) classes, as
the leafs is already handled by \fB(1)\fR. Right back up in yo muthafuckin ass. Still, itz perfectly possible to
create a leaf class without realtime service, n' up in such a cold-ass lil case tha caveats will
naturally extend ta leaf classes as well.

.SH ABBREVIATIONS
For tha remainin part of tha document, we'll use followin shortcuts:
.nf
.RS 4

RT \- realtime
LS \- linkshare
UL \- upperlimit
SC \- steez curve
.fi
.
.SH "BASICS OF HFSC"
.
To KNOW how tha fuck HFSC works, we must first introduce a steez curve.
Overall, itz a nondecreasin function of some time unit, returnin tha amount
of
service (an allowed or allocated amount of bandwidth) at some specific point in
time. Da purpose of it should be subconsciously obvious: if a cold-ass lil class was
allowed ta transfer not less than tha amount specified by its steez curve,
then tha steez curve aint violated.

Still, we need mo' elaborate criterion than just tha above (although in
da most thugged-out generic case it can be reduced ta it). Da criterion has ta take two
things tha fuck into account:
.
.RS 4
.IP \(bu 4
idlin periods
.IP \(bu
the mobilitizzle ta "look back", so if durin current actizzle period tha steez curve is violated, maybe it
aint if we count excess bandwidth received durin earlier actizzle period(s)
.RE
.PP
Letz define tha criterion as bigs up:
.RS 4
.nf
.IP "\fB(1)\fR" 4
For each t1, there must exist t0 up in set B, so S(t1\-t0)\~<=\~w(t0,t1)
.fi
.RE
.
.PP
Here 'w' denotes tha amount of steez received durin some time period between t0
and t1. B be a set of all times, where a session becomes actizzle afta idling
period (further denoted as 'becomin backlogged'). For a cold-ass lil clearer picture,
imagine two thangs:
.
.RS 4
.IP \fBa)\fR 4
our session was actizzle durin two periods, wit a lil' small-ass time gap between them
.IP \fBb)\fR
as up in (a) yo, but wit a larger gap
.RE
.
.PP
Consider \fB(a)\fR: if tha steez received durin both periodz meets
\fB(1)\fR, then all is well. But what tha fuck if it don't do so durin tha 2nd
period, biatch? If tha amount of steez received durin tha 1st period is larger
than tha steez curve, then it might compensate fo' smalla steez during
the 2nd period \fIand\fR tha gap \- if tha gap is lil' small-ass enough.

If tha gap is larger \fB(b)\fR \- then itz less likely ta happen (unless the
excess bandwidth allocated durin tha 1st part was straight-up large). Right back up in yo muthafuckin ass. Still, the
larger tha gap \- tha less bangin-ass is what tha fuck happened up in tha past (e.g. 10
minutes ago) \- what tha fuck mattas is tha current traffic dat just started.

From HFSCz perspective, mo' bangin-ass be answerin tha followin question:
when should we start transferrin packets, so a steez curve of a cold-ass lil class is not
violated. Y'all KNOW dat shit, muthafucka! This type'a shiznit happens all tha time. Or rephrasin it: How tha fuck much X() amount of steez should a session
receive by time t, so tha steez curve aint violated. Y'all KNOW dat shit, muthafucka! This type'a shiznit happens all tha time. Function X() defined
as below is tha basic buildin block of HFSC, used in: eligible, deadline,
virtual\-time n' fit\-time curves. Of course, X() is based on equation
\fB(1)\fR n' is defined recursively:

.RS 4
.IP \(bu 4
At tha 1st backlogged period beginnin function X is initialized ta generic
service curve assigned ta a cold-ass lil class
.IP \(bu
At any subsequent backlogged period, X() is:
.nf
\fBmin(X() from previous period ; w(t0)+S(t\-t0) fo' t>=t0),\fR
.fi
\&... where t0 denotes tha beginnin of tha current backlogged period.
.RE
.
.PP
HFSC uses either linear, or two\-piece linear steez curves. In case of
linear or two\-piece linear convex functions (first slope < second slope),
min() up in Xz definizzle reduces ta tha 2nd argument. But up in case of two\-piece
concave functions, tha 1st argument might quickly become lesser fo' some
t>=t0. Note, dat fo' some backlogged period, X() is defined only from that
periodz beginning. We also define X^(\-1)(w) as smallest t>=t0, fo' which
X(t)\~=\~w. We gotta define it dis way, as X() is probably not a injection.

Da above generic X() can be one of tha following:
.
.RS 4
.IP "E()" 4
In realtime criterion, selects packets eligible fo' sending. If none are
eligible, HFSC will use linkshare criterion. I aint talkin' bout chicken n' gravy biatch. Eligible time \&'et' is calculated
with reference ta packets' headz ( et\~=\~E^(\-1)(w) ). It aint nuthin but based on RT
service curve, \fIbut up in case of a cold-ass lil convex curve, uses its 2nd slope only.\fR
.IP "D()"
In realtime criterion, selects da most thugged-out suitable packet from tha ones chosen
by E(). Deadline time \&'dt' correspondz ta packets' tails
(dt\~=\~D^(\-1)(w+l), where \&'l' is packetz length). Based on RT service
curve.
.IP "V()"
In linkshare criterion, arbitrates which packet ta bust next. Note dat V() is
function of a virtual time \- peep \fBLINKSHARE CRITERION\fR section for
details. Virtual time \&'vt' correspondz ta packets' heads
(vt\~=\~V^(\-1)(w)). Based on LS steez curve.
.IP "F()"
An extension ta linkshare criterion, used ta limit at which speed linkshare
criterion be allowed ta dequeue. Fit\-time 'ft' correspondz ta packets' heads
as well (ft\~=\~F^(\-1)(w)). Based on UL steez curve.
.RE

Be shizzle ta make clean distinction between sessionz RT, LS n' UL service
curves n' tha above "utility" functions.
.
.SH "REALTIME CRITERION"
.
RT criterion \fIignores class hierarchy\fR n' guarantees precise bandwidth and
delay allocation. I aint talkin' bout chicken n' gravy biatch. We say dat a packet is eligible fo' sending, when the
current real
time is lata than tha eligible time of tha packet. From all eligible packets, tha one most
suited fo' bustin  is tha one wit tha shortest deadline time. This sounds
simple yo, but consider tha followin example:

Interface 10Mbit, two classes, both wit two\-piece linear steez curves:
.RS 4
.IP \(bu 4
1st class \- 2Mbit fo' 100ms, then 7Mbit (convex \- 1st slope < 2nd slope)
.IP \(bu
2nd class \- 7Mbit fo' 100ms, then 2Mbit (concave \- 1st slope > 2nd slope)
.RE
.PP
Assume fo' a moment, dat we only use D() fo' both findin eligible packets,
and choosin da most thugged-out fittin one, thus eligible time would be computed as
D^(\-1)(w) n' deadline time would be computed as D^(\-1)(w+l). If tha 2nd
class starts bustin  packets 1 second afta tha 1st class, itz of course
impossible ta guarantee 14Mbit, as tha intercourse capabilitizzle is only 10Mbit.
Da only workaround up in dis scenario is ta allow tha 1st class ta bust the
packets earlier dat would normally be allowed. Y'all KNOW dat shit, muthafucka! Thatz where separate E() comes
to help. Puttin all tha math aside (see HFSC paper fo' details), E() fo' RT
concave steez curve is just like D() yo, but fo' tha RT convex steez curve \-
itz constructed rockin \fIonly\fR RT steez curvez 2nd slope (in our example
 7Mbit).

Da effect of such E() \- packets is ghon be busted earlier, n' all up in tha same time
D() \fIwill\fR be updated \- so tha current deadline time calculated from it
will be later n' shit. Thus, when tha 2nd class starts bustin  packets later, both
the 1st n' tha 2nd class is ghon be eligible yo, but tha 2nd sessionz deadline
time is ghon be smalla n' its packets is ghon be busted first. When tha 1st class
becomes idle at some lata point, tha 2nd class is ghon be able ta "buffer" up
again fo' lata actizzle period of tha 1st class.

A short remark \- up in a thang, where tha total amount of bandwidth
available on tha intercourse is larger than tha allocated total realtime parts
(imagine a 10 Mbit intercourse yo, but 1Mbit/2Mbit n' 2Mbit/1Mbit classes), tha sole
speed of tha intercourse could suffice ta guarantee tha times.

Important part of RT criterion is dat apart from uppimpin its D() n' E(),
also V() used by LS criterion is updated. Y'all KNOW dat shit, muthafucka! This type'a shiznit happens all tha time. Generally tha RT criterion is
secondary ta LS one, n' used \fIonly\fR if there be a a risk of violatin precise
realtime requirements, n' you can put dat on yo' toast. Right back up in yo muthafuckin ass. Still, tha "participation" up in bandwidth distributed by
LS criterion is there, so V() has ta be updated along tha way. LS criterion can
than properly compensate fo' non\-ideal fair pluggin thang, caused by RT
scheduling. If you use UL steez curve its F() is ghon be updated as well (UL
service curve be a extension ta LS one \- peep \fBUPPERLIMIT CRITERION\fR
section).

Anyway \- careless justification of LS n' RT steez curves can lead to
potentially undesired thangs (see CORNER CASES fo' examples). This wasn't
the case up in HFSC paper where LS n' RT steez curves couldn't be specified
separately.

.SH "LINKSHARING CRITERION"
.
LS criterionz task is ta distribute bandwidth accordin ta specified class
hierarchy. Contrary ta RT criterion, there're no comparisons between current
real time n' virtual time \- tha decision is based solely on direct comparison
of virtual timez of all actizzle subclasses \- tha one wit tha smallest vt wins
and gets scheduled. Y'all KNOW dat shit, muthafucka! One immediate conclusion from dis fact is dat absolute
values don't matta \- only ratios between dem (so fo' example, two children
classes wit simple linear 1Mbit steez curves will git tha same treatment
from LS criterionz perspective, as if they was 5Mbit). Da other conclusion
is, dat up in perfectly fluid system wit linear curves, all virtual times across
whole class hierarchy would be equal.

Why is VC defined up in term of virtual time (and what tha fuck is it)?

Imagine a example: class A wit two lil pimps \- A1 n' A2, both wit letz say
10Mbit SCs. If A2 is idle, A1 receives all tha bandwidth of A (and update its
V() up in tha process). When A2 becomes active, A1z virtual time be already
\fIfar\fR lata than A2z one. Considerin tha type of decision made by LS
criterion, A1 would become idle fo' a long-ass time. We can workaround this
situation by adjustin virtual time of tha class becomin actizzle \- our phat asses do that
by gettin such time "up ta date" yo. HFSC uses a mean of tha smallest n' the
biggest virtual time of currently actizzle lil pimps fit fo' sendin fo' realz. As itz not
real time no mo' (excludin trivial case of thang where all classes become
actizzle all up in tha same time, n' never become idle), itz called virtual time.

Such approach has its price though cause I gots dem finger-lickin' chickens wit tha siz-auce. Da problem be analogous ta what tha fuck was
presented up in previous section n' is caused by non\-linearitizzle of service
curves:
.IP 1) 4
either itz impossible ta guarantee steez curves n' satisfy fairness
durin certain time periods:

.RS 4
Recall tha example from RT section, slightly modified (with 3Mbit slopes
instead of 2Mbit ones):

.IP \(bu 4
1st class \- 3Mbit fo' 100ms, then 7Mbit (convex \- 1st slope < 2nd slope)
.IP \(bu
2nd class \- 7Mbit fo' 100ms, then 3Mbit (concave \- 1st slope > 2nd slope)

.PP
They sum up sickly ta 10Mbit \- tha intercoursez capacity. But if we wanted ta only
use LS fo' guarantees n' fairnizz \- it simply won't work. In LS context,
only V() is used fo' makin decision which class ta schedule. If tha 2nd class
becomes actizzle when tha 1st one is up in its second slope, tha fairnizz will be
preserved \- ratio is ghon be 1:1 (7Mbit:7Mbit) yo, but LS itself iz of course
unable ta guarantee tha absolute joints theyselves \- as it would gotta go
beyond of what tha fuck tha intercourse is capable of.
.RE

.IP 2) 4
and/or itz impossible ta guarantee steez curvez of all classes all up in tha same
time [fairly or not]:

.RS 4

This is similar ta tha above case yo, but a lil' bit mo' subtle. Us thugs will consider two
subtrees, arbitrated by they common (root here) parent:

.nf
R (root) -\ 10Mbit

A  \- 7Mbit, then 3Mbit
A1 \- 5Mbit, then 2Mbit
A2 \- 2Mbit, then 1Mbit

B  \- 3Mbit, then 7Mbit
.fi

R arbitrates between left subtree (A) n' right (B) fo' realz. Assume dat A2 n' B are
constantly backlogged, n' at some lata point A1 becomes backlogged (when all
other classes is up in they 2nd linear part).

What happens now, biatch? B (choice made by R) will \fIalways\fR git 7 Mbit as R is
only (obviously) concerned wit tha ratio between its direct lil' thugs. Thus A
subtree gets 3Mbit yo, but its lil pimps would want (at tha point when A1 became
backlogged) 5Mbit + 1Mbit. Thatz of course impossible, as they can only get
3Mbit cuz of intercourse limitation.

In tha left subtree \- our crazy asses have tha same thang as previously (fair split
between A1 n' A2 yo, but violated guarantees) yo, but up in tha whole tree \- there's
no fairnizz (B gots 7Mbit yo, but A1 n' A2 gotta fit together up in 3Mbit) and
therez no guarantees fo' all classes (only B gots what tha fuck it wanted). Even if we
violated fairnizz up in tha A subtree n' set A2z steez curve ta 0, A1 would
still not git tha required bandwidth.
.RE
.
.SH "UPPERLIMIT CRITERION"
.
UL criterion be a extensions ta LS one, dat permits bustin  packets only
if current real time is lata than fit\-time ('ft'). Right back up in yo muthafuckin ass. So tha modified LS
criterion becomes: chizzle tha smallest virtual time from all actizzle children,
such dat fit\-time < current real time also holds. Fit\-time is calculated
from F(), which is based on UL steez curve fo' realz. As you can see, its role is
kinda similar ta E() used up in RT criterion. I aint talkin' bout chicken n' gravy biatch fo' realz. Also, fo' obvious reasons \- you
can't specify UL steez curve without LS one.

Da main purpose of tha UL steez curve is ta limit HFSC ta bandwidth available on the
upstream routa (think adsl home modem/router, n' linux server as
NAT/firewall/etc. wit 100Mbit+ connection ta mentioned modem/router).
Typically, itz used ta create a single class directly under root, setting
a linear UL steez curve ta available bandwidth \- n' then bustin yo' class
structure from dat class downwards. Of course, you free ta add a UL service
curve (linear or not) ta any class wit LS criterion.

An blingin part bout tha UL steez curve is dat whenever at some point up in time
a class don't qualify fo' linksharin cuz of its fit\-time, tha next time it
does qualify it will update its virtual time ta tha smallest virtual time of
all actizzle lil pimps fit fo' linksharing. This way, one of tha main thangs tha LS
criterion tries ta big up \- equalitizzle of all virtual times across whole
hierarchy \- is preserved (in perfectly fluid system wit only linear curves,
all virtual times would be equal).

Without that, 'vt' would lag behind other virtual times, n' could cause
problems. Consider a intercourse wit a cold-ass lil capacitizzle of 10Mbit, n' tha followin leaf classes
(just up in case you skippin dis text quickly \- dis example shows behavior
that \f(BIdoesn't happen\fR):

.nf
A \- ls 5.0Mbit
B \- ls 2.5Mbit
C \- ls 2.5Mbit, ul 2.5Mbit
.fi

If B was idle, while A n' C was constantly backlogged, A n' C would normally
(as far as LS criterion is concerned) divide bandwidth up in 2:1 ratio. But due
to UL steez curve up in place, C would git at most 2.5Mbit, n' A would git the
remainin 7.5Mbit. Da longer tha backlogged period, tha mo' tha virtual times of
A n' C would drift apart. If B became backlogged at some lata point up in time,
its virtual time would be set ta (A's\~vt\~+\~C's\~vt)/2, thus blockin A from
sendin any traffic until Bz virtual time catches up wit A.
.
.SH "SEPARATE LS / RT SCs"
.
Another difference from tha original gangsta HFSC paper is dat RT n' LS SCs can be
specified separately. Mo'over, leaf classes is allowed ta have only either
RT SC or LS SC. For interior classes, only LS SCs make sense: any RT SC will
be ignored.
.
.SH "CORNER CASES"
.
Separate steez curves fo' LS n' RT criteria can lead ta certain traps
that come from "fighting" between ideal linksharin n' enforced realtime
guarantees. Those thangs didn't exist up in original gangsta HFSC paper, where
specifyin separate LS / RT steez curves was not discussed.

Consider a intercourse wit a 10Mbit capacity, wit tha followin leaf classes:

.nf
A \- ls 5.0Mbit, rt 8Mbit
B \- ls 2.5Mbit
C \- ls 2.5Mbit
.fi

Imagine A n' C is constantly backlogged. Y'all KNOW dat shit, muthafucka! As B is idle, A n' C would divide
bandwidth up in 2:1 ratio, thankin bout LS steez curve (so up in theory \- 6.66 and
3.33) fo' realz. Alas RT criterion takes priority, so A will git 8Mbit n' LS will be
able ta compensate class C fo' only 2 Mbit \- dis will cause discrepancy
between virtual timez of A n' C.

Assume dis thang lasts fo' a long-ass time wit no idle periods, and
suddenly B becomes active. Bz virtual time is ghon be updated to
(A's\~vt\~+\~C's\~vt)/2, effectively landin up in tha middle between Az n' C's
virtual time. Da effect \- B, havin no RT guarantees, is ghon be punished and
will not be allowed ta transfer until Cz virtual time catches up.

If tha intercourse had a higher capacity, fo' example 100Mbit, dis example
would behave perfectly fine though.

Letz look a lil' bit closer all up in tha above example \- it "cleverly" invalidates one
of tha basic thangs LS criterion tries ta big up \- equalitizzle of all virtual
times across class hierarchy. Leaf classes without RT steez curves are
literally left ta they own fate (governed by messed up virtual times).

Also, it don't make much sense. Class A will always be guaranteed up to
8Mbit, n' dis is mo' than any absolute bandwidth dat could happen from its
LS criterion (excludin trivial case of only A bein active). If tha bandwidth
taken by A is smalla than absolute value from LS criterion, tha unused part
will be automatically assigned ta other actizzle classes (as A has idlin periods
in such case). Da only "advantage" is, dat even up in case of low bandwidth on
average, bursts would be handled all up in tha speed defined by RT criterion. I aint talkin' bout chicken n' gravy biatch. Right back up in yo muthafuckin ass. Still,
if extra speed is needed (e.g. cuz of latency), non linear steez curves
should be used up in such case.

In tha other lyrics: tha LS criterion is meaningless up in tha above example.

Yo ass can quickly "workaround" it by makin shizzle each leaf class has RT service
curve assigned (thus guaranteein all of dem will git some bandwidth) yo, but it
doesn't make it any mo' valid.

Keep it realz in mind - if you use nonlinear curves n' irregularitizzles explained above
happen \fIonly\fR up in tha straight-up original gangsta segment, then there be a lil wack with
"overusing" RT curve a funky-ass bit:

.nf
A \- ls 5.0Mbit, rt 9Mbit/30ms, then 1Mbit
B \- ls 2.5Mbit
C \- ls 2.5Mbit
.fi

Here, tha vt of A will "spike" up in tha initial period yo, but then A aint NEVER gonna git more
than 1Mbit until B & C catch up. Then every last muthafuckin thang is ghon be back ta normal.
.
.SH "LINUX AND TIMER RESOLUTION"
.
In certain thangs, tha schedula can throttle itself n' setup so
called watchdog ta wakeup dequeue function at some time later n' shit. In case of HFSC
it happens when fo' example no packet is eligible fo' scheduling, n' UL
service curve is used ta limit tha speed at which LS criterion be allowed to
dequeue packets, n' you can put dat on yo' toast. It aint nuthin but called throttling, n' accuracy of it is dependent on
how tha kernel is compiled.

There're 3 blingin options up in modern kernels, as far as timers' resolution
goes: \&'tickless system', \&'high resolution timer support' n' \&'timer
frequency'.

If you have \&'tickless system' enabled, then tha timer interrupt will trigger
as slowly as possible yo, but each time a schedula throttlez itself (or any
other part of tha kernel needz betta accuracy), tha rate is ghon be increased as
needed / possible. Da ceilin is either \&'timer frequency' if \&'high
resolution timer support' aint available or not compiled in, or it's
hardware dependent n' can go \fIfar\fR beyond tha highest \&'timer frequency'
settin available.

If \&'tickless system' aint enabled, tha timer will trigger at a gangbangin' fixed rate
specified by \&'timer frequency' \- regardless if high resolution timers are
or aren't available.

This is blingin ta keep dem settings up in mind, as up in scenario like: no
tickless, no HR timers, frequency set ta 100hz \- throttlin accuracy would be
at 10ms. Well shiiiit, it don't automatically mean you would be limited ta ~0.8Mbit/s
(assumin packets at ~1KB) \- as long as yo' queues is prepared ta cover for
timer inaccuracy. Of course, up in case of e.g. locally generated UDP traffic \-
appropriate socket size is needed as well. Right back up in yo muthafuckin ass. Short example ta make it more
understandable (assume hardcore anti\-schedule settings \- HZ=100, no HR
timers, no tickless):

.nf
tc qdisc add dev eth0 root handle 1:0 hfsc default 1
tc class add dev eth0 parent 1:0 classid 1:1 hfsc rt m2 10Mbit
.fi

Assumin packet of ~1KB size n' HZ=100, dat averages ta ~0.8Mbit \- anything
beyond it (e.g. tha above example wit specified rate over 10x larger) will
require appropriate queuin n' cause bursts every last muthafuckin ~10 ms fo' realz. As you can
imagine, any HFSCz RT guarantees is ghon be seriously invalidated by dis shit.
Aforementioned example is mainly blingin if you deal wit oldschool hardware \- as
is particularly ghettofab fo' home server chores. Even then, you can easily
set HZ=1000 n' have straight-up accurate schedulin fo' typical adsl speeds.

Anythang modern (apic or even hpet msi based timers + \&'tickless system')
will provide enough accuracy fo' superb 1Gbit scheduling. For example, on one
of mah skanky dual-core AMD boardz I have tha followin settings:

.nf
tc qdisc add dev eth0 parent root handle 1:0 hfsc default 1
tc class add dev eth0 parent 1:0 classid 1:1 hfsc rt m2 300mbit
.fi

And a simple:

.nf
nc \-u dst.host.com 54321 </dev/zero
nc \-l \-p 54321 >/dev/null
.fi

\&...will yield tha followin effects over a period of ~10 secondz (taken from
/proc/interrupts):

.nf
319: 42124229   0  HPET_MSI\-edge  hpet2 (before)
319: 42436214   0  HPET_MSI\-edge  hpet2 (afta 10s.)
.fi

Thatz roughly 31000/s. Now compare it wit HZ=1000 setting. Da obvious
drawback of it is dat cpu load can be rather high wit servicin that
many timer interrupts, n' you can put dat on yo' toast. Da example wit 300Mbit RT steez curve on 1Gbit link is
particularly skanky, as it requires a shitload of throttlin wit minuscule delays.

Also note dat itz just a example showin tha capabilitizzlez of current hardware.
Da above example (essentially a 300Mbit TBF emulator) is pointless on a internal
interface ta begin with: yo big-ass booty is ghon pretty much always want a regular LS service
curve there, n' up in such a scenario HFSC simply don't throttle at all.

300Mbit RT steez curve (selected columns from mpstat \-P ALL 1):

.nf
10:56:43 PM  CPU  %sys     %irq   %soft   %idle
10:56:44 PM  all  20.10    6.53   34.67   37.19
10:56:44 PM    0  35.00    0.00   63.00    0.00
10:56:44 PM    1   4.95   12.87    6.93   73.27
.fi

So, up in tha rare case you need dem speedz wit only a RT steez curve, or wit a UL
service curve: remember tha drawbacks.
.
.SH "CAVEAT: RANDOM ONLINE EXAMPLES"
.
For reasons unknown (though well guessed), nuff examplez you can google ludd to
overuse UL criterion n' shiznit it up in every last muthafuckin node possible. This make no sense
and works against what tha fuck HFSC tries ta do (and do pretty damn well). Use UL
where it make sense: on tha uppermost node ta match upstream routerz uplink
capacity. Or up in special cases, like fuckin testin (limit certain subtree ta some
speed), or hustlas dat must never git mo' than certain speed. Y'all KNOW dat shit, muthafucka! In tha last
case you can probably big up tha same by just rockin a RT criterion without LS+UL
on leaf nodes.

As fo' tha routa case - remember itz phat ta differentiate between "traffic to
router" (remote console, wizzy config, etc.) n' "outgoin traffic", so for
example:

.nf
tc qdisc add dev eth0 root handle 1:0 hfsc default 0x8002
tc class add dev eth0 parent 1:0 classid 1:999 hfsc rt m2 50Mbit
tc class add dev eth0 parent 1:0 classid 1:1 hfsc ls m2 2Mbit ul m2 2Mbit
.fi

\&... so "internet" tree under 1:1 n' "routa itself" as 1:999
.
.SH "LAYER2 ADAPTATION"
.
Please refer ta \fBtc\-stab\fR(8)
.
.SH "SEE ALSO"
.
\fBtc\fR(8), \fBtc\-hfsc\fR(8), \fBtc\-stab\fR(8)

Please direct bugreports n' patches to: <net...@vger.kernel.org>
.
.SH "AUTHOR"
.
Manpage pimped by Michal Soltys (sol...@ziu.info)
